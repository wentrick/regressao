---
title: "Exercicio Regressao Multipla Sala"
author: "Davi Wentrick Feijó - 200016806"
date: "2023-06-02"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse,Matrix,knitr)
```

### Regressao Linear Multipla

Vamos usar esses dados:
```{r echo=FALSE}
#modelo linear multiplo
area = c(1:15)
safra_de_trigo = c(40,38,50,49,50,55,70,55,45,65,72,70,65,80,75)
fertilizante = c(100,150,200,250,300,350,400,410,450,500,550,600,650,700,800)
chuva = c(10,10,20,20,10,20,30,20,10,20,20,30,20,30,30)

dados = data.frame(area,safra_de_trigo,fertilizante,chuva) 

dados2 <- dados %>% #somente para ficar bonito no documento
  rename("Area" = area , "Safra de Trigo" = safra_de_trigo ,"Fertilizante" = fertilizante , "Chuva" = chuva )
```


```{r echo=FALSE}
#kable(dados,col.names = c('Area', 'Safra de Trigo', 'Fertilizante', 'Chuva')) 
dados2
```

#### Especificar os elementos dos vetores e matrizes do problema 

```{r}
n <- nrow(dados) # Number of observations
n
```


Nosso Y será a safra de trigo:

```{r echo=FALSE}
Y <- dados$safra_de_trigo
Y <- as.matrix(Y)
Y
```


E o X será o fertilizante e o indice de chuvas:

```{r echo=FALSE}
X <- cbind(dados$fertilizante,dados$chuva)
X
```

podemos adicionar na matriz X o vetor de 1 para ser nosso intecepto.

```{r}
X <- cbind(rep(1,n), X) 
X                     
```

Vamos definir nossa matris J que sera com composta inteiramente por 1 e sera $n \times n$ (n sendo o numero de observacoes)

```{r}
J = matrix(data = 1, nrow = n, ncol = n)
head(J)
```


Agora podemos encontrar nosso vetor de Betas sabendo que ele pode ser calculado da seguinte forma:

$$
\beta = (X^TX)^{-1}X^TY
$$
```{r}
#encontrando XTX

XTX = t(X) %*% X
XTX

#encontrando XTY

XTY = t(X) %*% Y
XTY

#encontrando a inversa de XTX

XTX_inv = solve(XTX)
XTX_inv

#encnontrando a matriz de parametros Beta (ela contem o Beta 0 e o Beta 1 ou todos os beta no caso de uma regressao multipla)

beta = XTX_inv %*% t(X) %*% Y #em partes

beta = solve(t(X) %*% X) %*% t(X) %*% Y #direto

beta
```

Com a matriz de betas podemos ajustar os valores esperados do modelo $\hat Y$:

```{r}
#valores estimados pelo modelo (y chapeu)
Yhat <- X %*% beta # Fitted Values
Yhat
```

Em seguida podemos calcular nossos residuos

```{r}
#residuos do modelo
e <- Y - Yhat # Residuals
e
```

Podemos realizar a ANOVA do modelo para isso precisaremos calcular as seguintes somas de quadrados

* Soma de quadrados da regressao (SSR ou SQR)
  + $\hat{\beta}^TX^TY-\frac{1}{n}Y^TJY$
* Soma de quadrados do residuo (SSE ou SQE)
  + $\varepsilon^T\varepsilon$ ou $Y^TY-\hat{\beta}^TX^TY$
* Soma de quadrados total (SST ou SQT)
  + $SSE+SSR$
  
```{r}
sse = t(e) %*% e #soma de quadrados do residuo
sse = t(Y) %*% Y - t(beta) %*% t(X) %*% Y #segunda forma de calcular
sse

ssr = t(beta) %*% t(X) %*% Y - (1/n) * (t(Y) %*% J %*% Y) #soma de quadrados da regressao
ssr

sst = ssr +sse  #soma de quadrados total
sst
```

Em seguida temos que encontrar os quadrados medios:

* Quadrado Médio da regressao (MSR ou QMR)
  + $\frac{SSR}{p-1}$
* Quadrado Médio do residuo (MSE ou QME)
  + $\frac{SSE}{n-p}$

Onde $n$ é o número de observacoes e $p$ o número de parametros (variaveis) do modelo

```{r}
p = length(beta)
```
Vamos obter os graus de liberdade da regressao, residuo e total

```{r}
glreg = p-1
glres = n-p
gltot = n-1
```

```{r echo=FALSE}
cat("A quantiade de graus de liberdade relacionado a regressao é:",glreg)
cat("A quantiade de graus de liberdade relacionado aos residuos é:",glres)
cat("A quantiade de graus de liberdade relacionado ao total é:",gltot)
```



```{r}
msr = ssr/(p-1)
msr
```

```{r}
mse = sse/(n-p)
mse
```
Vamos calcular nosso $R^2$:

```{r}
r2 = ssr / sst
r2
```



Vamos calcular a soma de quadrados extra, para isso vamos ajustar um modelo somente com a variavel fertilizante e ver quanto ela explica por si só e quato que adicionar a variavel chuva vai incrementar nessa explicação. Para agilizar vamos calcular usando o a função lm()

```{r}
modelo_1 = lm(safra_de_trigo ~ fertilizante ,data = dados)
ssr1 <- sum((fitted(modelo_1) - mean(dados$safra_de_trigo))^2)

ssrx1x2 = ssr - ssr1
```

Podemos aproveitar esses calculos para encontrar o coeficiente de determinação parcial:

$$
R^2_{Y 2|1} = \frac{SSR(X1|X2)}{SSE(X2)}
$$

```{r}
modelo_2 = lm(safra_de_trigo ~ chuva ,data = dados)
sse2 <- sum((fitted(modelo_2) - dados$safra_de_trigo)^2)

r2_x2x1 = ssrx1x2/sse2
r2_x2x1
```

Em seguida podemos calcular os valores F observados:

```{r}
f_value_reg = msr/mse
f_value_reg
f_value_x1 = ssr1/mse
f_value_x1
f_value_x1x2 = ssrx1x2/mse
f_value_x1x2
```

Vamos calcular os p-valores do teste F

```{r}
p_value_reg = pf(f_value_reg,glreg,glres,lower.tail = F)
p_value_x1 = pf(f_value_x1,1,glres,lower.tail = F)
p_value_x1x2 = pf(f_value_x1x2,1,glres,lower.tail = F)
```

```{r echo=FALSE}
cat("O p-valor do teste F da Regressao completa é:",p_value_reg)
cat("O p-valor do teste F da Regressao com X1 é:",p_value_x1)
cat("O p-valor do teste F da Regressao com a adicção de X2 em X1:",p_value_x1x2)
```



Podemos apresentar nossa tabela da anova
```{r echo=FALSE}
#tabela anova na mao
anova_table <- data.frame(Fonte_de_variacao = c("Regressao","X1","X1|X2","Residuos", "Total"),
                          GL = c(glreg,1,1,glres,gltot),
                          SS = c(ssr,ssr1,ssrx1x2,sse,sst),
                          MQ = c(round(msr,2),round(ssr1/1,2),round(ssrx1x2/1,2),round(mse,2), ''),
                          F_Value = c(round(f_value_reg,4),round(f_value_x1,4),round(f_value_x1x2,4),"",""),
                          F_Value = c(round(p_value_reg,10),round(p_value_x1,10),round(p_value_x1x2,6),"",""),
                          stringsAsFactors = FALSE)
rownames(anova_table) <- NULL

anova_table
```
Vamos comparar com a anova do R:

```{r}
modelo_completo = lm(safra_de_trigo ~ fertilizante + chuva ,data = dados)
anova(modelo_completo)
```


Estimador da variancia residual

$$
\hat\sigma^2 = \frac{\sum^n_{i=1}e_i^2}{n-p} = \frac{SSE}{n-p} = MSE
$$
$$
MSE = \frac{Y^TY-\hat\beta^TX^TY}{n-p}
$$


```{r}
mse
```


Podemos calcular a $V(\hat\beta)$, que será uma matriz de covariancias onde a diagonal tera as variancias dos betas, utilizando a seguinte formula:

$$
V(\hat\beta) = \hat\sigma^2(X^TX)^{-1}
$$
```{r}
var_beta = as.numeric(mse) * solve(t(X)%*%X) #tive que colocar como numerico 
                                             #pois o r entende que é uma matriz 1x1
round(var_beta,4)

round(diag(var_beta),4)
```

### Intervalos de Confianca para $\beta_k$


Sabemos que podem ser calculados por meio das seguintes formulas:

$$
\frac{\hat\beta_k - \beta_k}{S(\hat\beta_k)} \sim \text{Student com (n-p) g.l}
$$

O intervalo de confiança $(1-\alpha)$ pode ser escrito como:

$$
\beta_k \in (\hat\beta_k \mp t_{1-\alpha/2}S(\hat\beta_k))
$$
onde:

$$
S(\hat\beta_k) = \sqrt{V(\beta_k)}
$$
Vamos calcular o intervalo de confianca de 90% para $\beta_1$

```{r}
alfa = 0.10
#t_value = qt(1-(alfa/2))

```


